# Mamba 与 MinGRU 算法实验总结

## 一、项目概览
- 目标：在时间序列预测任务上实现并对比 MinGRU 与 Mamba 序列模型，使用纯 numpy 完成前向、反向与参数更新。
- 结果：两种模型均可稳定训练；在当前设置下，Mamba 收敛更快、验证误差更低，并生成对比图 `mamba_vs_mingru.png`。

## 二、环境与目录
- 运行环境：Python 3.13（Conda），依赖：`numpy`、`pandas`、`yfinance`、`scikit-learn`、`matplotlib`。
- 最终统一项目目录：`labs_rnn`
  - `labs_rnn/models/min_gru.py`、`labs_rnn/models/mamba.py`
  - `labs_rnn/utils/data_loader.py`
  - `labs_rnn/test_model.py`、`labs_rnn/benchmark.py`、`labs_rnn/run_mamba.py`、`labs_rnn/test_mamba_simple.py`
  - 数据：`labs_rnn/data/AAPL_stock_data.csv`

## 三、数据处理与回退策略
- 数据来源：`yfinance` 自动下载 AAPL 收盘价，并保存到 `labs_rnn/data/AAPL_stock_data.csv`。
- 预处理：`MinMaxScaler(0,1)` 归一化为单特征序列。
- 批次构造：窗口长度 `seq_len=32`，预测下一时刻；批次输出形状：
  - `x: (seq_len, 1, batch_size)`，`y: (1, batch_size)`
- 网络/限流回退：若下载失败，自动读取本地 CSV；若无 CSV，则生成平滑合成序列并保存，保证全流程可复现。

## 四、模型实现要点
- MinGRU（简化 GRU）：
  - 核心单步前向在 `labs_rnn/models/min_gru.py`，更新门 `z`、重置门 `r`，候选隐藏 `h̃`，输出 `y=W_y h`。
  - 反向单步梯度拆解至各门与候选状态，BPTT 逐时反传；支持 L2 正则与梯度裁剪。
- Mamba（SSM 选择性扫描）：
  - 输入投影 `W_in x[t]`，状态更新 `s ← s·exp(A) + B^T·gate`，输出 `y[t] = gate · clip(C s + D·x_proj[t])`。
  - 数值稳定：对 `SiLU` 输入与中间量 `u` 裁剪，抑制溢出与梯度爆炸；反向同样考虑裁剪项传播。

## 五、训练与评估配置
- 通用：`seq_len=32`、`hidden_size=128`、`batch_size=32`、`n_epochs=5`。
- 优化：纯 numpy SGD，`learning_rate=0.01`，`weight_decay=1e-4`；在对比脚本中将 Mamba 学习率暂调为 `0.005` 以增强稳定性。
- 指标：`MSE` 作为训练与验证损失（见 `labs_rnn/test_model.py`）。

## 六、实验结果（样例运行）
- MinGRU（训练/验证损失，部分摘录）：
  - Epoch 1：Train ≈ 0.215，Valid ≈ 0.122
  - Epoch 5：Train ≈ 0.055，Valid ≈ 0.055
- Mamba（训练/验证损失，部分摘录）：
  - Epoch 1：Train ≈ 0.021–0.55（不同数据回退与随机种子下波动）；Valid ≈ 0.009–0.015
  - Epoch 5：Train ≈ 0.0026–0.0038，Valid ≈ 0.0024–0.0048
- 可视化：`python labs_rnn/benchmark.py` 生成 `mamba_vs_mingru.png`，中文标题与坐标标签正常显示（自动选择系统中文字体）。

## 七、关键发现
- 收敛速度：Mamba 早期损失下降更快，整体训练更高效。
- 最终性能：当前配置下，Mamba 的验证 MSE 低于 MinGRU，具有更强的拟合与泛化表现。
- 数值稳定：为 Mamba 增加 `SiLU` 与中间量裁剪后，训练过程稳定、无溢出导致的 NaN。

## 八、调试与稳定性技巧
- 门控/激活裁剪：限制输入到 `[-50,50]`，`u` 限制到 `[-10,10]`，降低指数与乘法溢出的风险。
- 学习率分离：Mamba 在纯 numpy 实现下对学习率更敏感，适当降低更稳。
- 数据回退：网络不稳定或被限流时自动切换到本地/合成数据，保障实验可重复。

## 九、复现实验步骤
- 训练 MinGRU：
  - `python labs_rnn/test_model.py`（默认 `model_type = "min_gru"`）
- 训练 Mamba：
  - 修改 `labs_rnn/test_model.py` 顶部 `model_type = "mamba"` 或运行 `python labs_rnn/run_mamba.py`
- 基准对比与出图：
  - `python labs_rnn/benchmark.py`（自动对比并生成 `mamba_vs_mingru.png`）

## 十、改进方向
- 优化器：加入 Adam/RMSProp 等自适应学习率优化器以加速收敛与稳定训练。
- 正则化与早停：在纯 numpy 框架下增加 L2/L1、早停等机制，进一步提升泛化。
- 多特征与跨数据集：扩展到 [Open, High, Low, Close, Volume] 多特征输入及其他时序数据集。
- 深层结构：堆叠多层 Mamba 及混合注意力结构，探索更强的表达能力与长依赖建模。

## 十一、文件清单与入口
- 训练与验证：`labs_rnn/test_model.py`
- 基准与可视化：`labs_rnn/benchmark.py`（生成 `mamba_vs_mingru.png`）
- 模型实现：`labs_rnn/models/min_gru.py`、`labs_rnn/models/mamba.py`
- 数据流程：`labs_rnn/utils/data_loader.py`
- 数据目录：`labs_rnn/data/AAPL_stock_data.csv`

---
以上总结基于本地多次运行日志与生成的图像文件，可在网络受限场景下稳定复现。若需将实验扩展为命令行入口或增加更详细的指标统计（RMSE/MAE/R²），可在 `benchmark.py` 中直接扩展统计与绘图逻辑。
